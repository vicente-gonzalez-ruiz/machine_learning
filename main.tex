\section{Min-max normalization}
\begin{equation}
  Y = \frac{X-\text{min}(X)}{\text{max}(X)-\text{min}(X)}.
\end{equation}

\section{Cross-entropy}
Cross-entropy is a way to measure the difference between two probability distributions — usually between the true labels and a model’s predicted probabilities.

In ML (especially in classification tasks), cross-entropy is commonly used as a loss function to quantify how well the predicted probability distribution matches the actual distribution (the true class labels).

It can be expressed as
\begin{equation}
  H(p,q) = -\mathbb{E}_p[\log q],
\end{equation}
where $\mathbb{E}_p$ is the expected value operator with respect to
the distribution $p$.

For discrete probability distributions $p$ and $q$ with the same support $\mathcal{X}$,
\begin{equation}
  H(p,q) = -\sum_{x\in\mathcal{X}}p(x)\log q(x),
\end{equation}
where $p(x)$ is the true probability of the label/class $x$ and $q(x)$ is the model predict probability for $x$. When there are only two classes/labels (binary classification), this equation boils down to
\begin{equation}
  H(p,q) = -(p\log q + (1-p)\log(1-q)),
\end{equation}
where $p$ is 0 or 1, and $p$ is the probability of the prediction for label 1.

In classification tasks we usually try to minimize the cross-entropy.

\section{Accuracy (Acc)}
The evaluation metric Accuracy (Acc, \emph{exactitud} in Spanish) evaluates the performance of a
classification model. Specifically, it measures the probability the model
makes correct predictions, and it is numerically defined as
\begin{equation}
  \text{Acc} = \frac{CoPr}{ToPr},
\end{equation}
where, the number of correct predictions
\begin{equation}
  \text{CoPr} = \text{TP} + \text{TN}
\end{equation}
and the total number of predictions
\begin{equation}
  \text{ToPr} = \text{TP} + \text{FP} + \text{TN} + \text{FN},
\end{equation}
where TP is the number of true positives, TN is the number of true
negatives, FP is the number of false positives, and FN is the number
of false negatives.

\section{Recall}
(\emph{recuperación} in Spanish)
\begin{equation}
  \text{R} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}

\section{Sensitivity (Se), recall or TPR}
Sensitivity, also known as the True Positive Rate (TPR) and as recall,
reveals how well a model caEn otras palabras, de todas las veces que la respuesta era "sí", ¿cuántas veces el modelo lo detectó?En otras palabras, de todas las veces que la respuesta era "sí", ¿cuántas veces el modelo lo detectó?n identify (classify) positive
instances. It is defined as
\begin{equation}
  \text{Se} = \frac{\text{TP}}{\text{TP} + \text{FN}}.
\end{equation}
In other words, out of all the times the answer was "yes," how many times was the model wrong?

\section{Specifity}
Specifity measures how well a model can correctly identify (classify)
negative instances, that is
\begin{equation}
  \text{Sp} = \frac{\text{TN}}{\text{TN} + \text{FP}}.
\end{equation}

\section{Precision}
This classification metric (\emph{precisión} in Spanish) measures the proportion of correctly predicted positive instances out of all instances predicted as positive, i.e., it is computed by
\begin{equation}
  \text{Pr} = \frac{\text{TP}}{\text{TP} + \text{FP}}.
\end{equation}
In other words, of all the times the model said "yes," how many times was it right?

\section{F1-score}
Classification metric that computes the harmonic mean of Pr and Se:
\begin{equation}
  \text{F1-score} = \frac{2\text{Pr}\text{Se}}{\text{Pr}+\text{Se}}.
\end{equation}
High F1-scores are correlated with a good equilibrium between precision and recall.

\section{Confusion matrix}
A table that summarizes the performance of a classification model by showing
\begin{table}{ccc}
  & Predicted Positive & Predicted Negative \\
  Actual Positive & TP & FN \\
  Actual Negative & FP & TN
\end{table}

\section{}
curva precisión-recuperación
\begin{equation}
  \text{AUC-PRC} = \sum_{i=1}^{t-1}(\text{R}_{i+1}-\text{R}_i)\frac{\text{P}_i+\text{P}_{i+1}}{2}
\end{equation}

\section{Epoch}
An epoch refers to one complete pass through the entire training dataset.

\section{Training dataset}
Collection of data used to teach the model. It's composed of input
features and their corresponding target labels.

\section{Validation dataset}
A subset of the training data used to evaluate the model's performance
when training.

\section{Test dataset}
Data used to evaluate the performance of a trained model.

\section{Batch}
During training, the dataset is ofted divided into smaller chunks
called batches.

\section{Training iteration}
One training iteration occurs when the during the training a single
batch of data has been used.

\section{Overfitting}
Overfitting happens when the model becomes too specialized to the
training dataset, performing poorly on unseen data.

\section{Early stopping}
To prevent overfitting, early stopping fialized the training when the
model's performance on the validation dataset starts to degrade.

\section{Batch normalization}
Batch normalization normalizes the activations of intermediate layers
within a mini-batch of data (only) during the training process. This
means it adjusts the mean and variance of the layer's
inputs. Algorithm:
\begin{enumerate}
\item Calculate batch mean $\mu_B$ and variance $\sigma^2_B$ for the input batch $B$.
\item Normalize the neuron activations using
  \begin{equation}
    \hat{x}_i = \frac{x_i-\mu_B}{\sqrt{\sigma^2_B+\epsilon}},
  \end{equation}
  where $x_i$ is the original  activation value, $\epsilon$ is a small
  constant  to  prevent  division  by zero,  and  $\hat{x}_i$  is  the
  normalized activation value.
\item Scale and shift the normalized activations with
  \begin{equation}
    y_i = \gamma\hat{x}_i+\beta,
  \end{equation}
  where $\gamma$ is a (learnable parameter) scaling factor, and
  $\beta$ (another learnable parameter) shifts the normalized
  activation.
\end{enumerate}

Batch normalization makes the learning process more stable and less
dependent on the initial weights (reduces internal covariate shift),
speed up the training process by allowing higher learning rates,
reduces the probability of vanishing and exploding gradients, acts as
a regularizer (reducing the need for other regularization techniques
like dropout), and reduces dependence on initialization (weights)
values.

\section{Cross-validation}

\section{Five-fold cross-validation}
Five-fold cross-validation is a common technique used to evaluate the performance of a machine learning model on a limited dataset and to get a more robust estimate of its generalization ability (how well it will perform on unseen data). Here's how it works:

\begin{enumerate}
\item Data Splitting: The original dataset is divided into five roughly equal-sized parts or "folds."

\item Training and Evaluation (Five Iterations): The experiment is run five times (the "five-fold"). In each iteration:
  \begin{enumerate}
  \item One fold is held out as the test set (or validation set). This is the data the model will be evaluated on in this particular run.
  \item The remaining four folds are used to train the model. The model learns from this larger portion of the data.
  \item The trained model is then evaluated on the held-out test fold, and the chosen metrics are recorded.
  \end{enumerate}
\item Averaging the Results: After all five iterations are complete, you will have five sets of metric scores (one from each test fold). The final reported metric in the section is the average of these five scores.
\end{enumerate}

\section{A word about convolution in DL libraries}
The true convolution of a signal $x$ and a kernel $w$ is defined as
\begin{equation}
  (x*w)[i] = \sum_k x[k]w[i-k].
\end{equation}
Notice that the kernel is \emph{flipped} (reversed). CNNs, however,
compute the cross-correlation, defined as:
\begin{equation}
  (x\star y)[i] = \sum_k x[i+k}w[k],
\end{equation}
of equivalently (depending on indexing):
\begin{equation}
  (x\star y)[i] = \sum_k x[k}w[i+k],
\end{equation}
and therefore, no \emph{flipping} of the kernel happens. In practice,
deep learning libraries (like PyTorch and Tensorflow) what really
compute as a \emph{convolution} is actually a
\emph{cross-correlation}.

\section{Conv1d}
For only one channel, and assuming no padding (``valid'' convolution), it is defined as
\begin{equation}
  y[i] = \sum_{k=0}^{K-1} w[k]x[is+k]+b
\end{equation}
where $x\in\mathcal{R}^L$ is the input digital 1D signal of length
$L$, $w\in\mathbcal{R}^K$ is the kernel (or filter) of length $K$,
$b\in\mathcal{R}$ is the bias, $n\in\mathcal{N}$ is the stride (how
much the filter moves at each step). if the signal $x$ is padded
(extended) with zeros at the boundaries, it is said that we are
computing the``same'' convolution.

When $x\in\mathcal{R}^{C_{\text{in}}L}$ has more than one channel and
a different kernel is used for each channel, then
\begin{equation}
  y[i] = \sum_{c=0}^{C_{\text{in}}-1}\sum_{k=0}^{K-1} w[c,k]x[c,is+k]+b
\end{equation}

Finally, each input channel can be convolved with $C_{\text{out}}$ kernels, generating
\begin{equation}
  y[m,i] = \sum_{c=0}^{C_{\text{in}}-1}\sum_{k=0}^{K-1} w[m,c,k]x[c,is+k]+b[m]
\end{equation}

\section{CNN}
Each convolutional layer learns different patterns and features at
various abstraction levels. The initial layers capture low-level features such
as edges and gradients, whereas the deeper layers capture more complex and
abstract features.

\section{Residual network}
For example Resnet \cite{}.

\section{Entropy}
Entropy is a measure of the uncertainty, randomness, or disorder
within a set of data or a probability distribution $X$, that can take
$N$ possible values $\{x_1,x_2,\cdots,x_n\}$. In the context of
information theory, it measures the average number of bits needed to
encode an event from a probability distribution. Entropy can be
computed as
\begin{equation}
  H(X) = -\sum_{i=1}^Mp(x_i)\log_b(p(x_i))
\end{equation}
where $p(x_i)$ is the probability of the $i$-th outcome, and $b$
determines the unit of entropy (``bits'' for $b=2$, ``nats'' for
$b=e$, and ``dits'' or ``hartleys'' for $b=10$).

\section{Cross-entropy}
Cross-entropy is a loss function to measure the difference between two
probability distributions for a given random variable or set of
events. In the context of classification models, it quantifies the
dissimilarity between the predicted probabilities and the true
labels. The lower, the better. The logarithmic nature of the
cross-entropy penalizes confident (small cross-entropy) but incorrect
predictions.

\subsection{Binary cross-entropy (only two classes)}
\begin{equation}
  L = -y\log(p)-(1-y)\log(1-p)
\end{equation}
where $y$ is the true label (0 or 1), and $p$ is the predicted probability of the positive class (class 1).

\subsection{Categorical cross-entropy (for multiple classes)}
\begin{equation}
  L = -\sum_{i=1}^M y_i\log(p_i)
\end{equation}
where $M$ is the number of classes, $y_i$ is the binary indicator (0 or 1) of whether the $i$-th class is the correct label for the data point, and $p_i$ is the predicted probability of the data point belonging to the $i$-th class.

\section{One-hot encoding}


