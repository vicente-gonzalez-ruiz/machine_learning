\section{Min-max normalization}
\begin{equation}
  Y = \frac{X-\text{min}(X)}{\text{max}(X)-\text{min}(X)}.
\end{equation}

\section{Cross-entropy}
\begin{equation}
  H(p,q) = -\mathbb{E}_p[\log q],
\end{equation}
where $\mathbb{E}_p$ is the expected value operator with respect to
the distribution $p$.

For discrete probability distributions $p$ and $q$ with the same support $\mathcal{X}$,
\begin{equation}
  H(p,q) = -\sum_{x\in\mathcal{X}}p(x)\log q(x).
\end{equation}

\section{Accuracy (Acc)}
The evaluation metric Accuracy (Acc, \emph{exactitud} in Spanish) evaluates the performance of a
classification model. Specifically, it measures the probability the model
makes correct predictions, and it is numerically defined as
\begin{equation}
  \text{Acc} = \frac{CoPr}{ToPr},
\end{equation}
where, the number of correct predictions
\begin{equation}
  \text{CoPr} = \text{TP} + \text{TN}
\end{equation}
and the total number of predictions
\begin{equation}
  \text{ToPr} = \text{TP} + \text{FP} + \text{TN} + \text{FN},
\end{equation}
where TP is the number of true positives, TN is the number of true
negatives, FP is the number of false positives, and FN is the number
of false negatives.

\section{Recall}
(\emph{recuperación} in Spanish)
\begin{equation}
  \text{R} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}

\section{Sensitivity (Se), recall or TPR}
Sensitivity, also known as the True Positive Rate (TPR) and as recall,
reveals how well a model caEn otras palabras, de todas las veces que la respuesta era "sí", ¿cuántas veces el modelo lo detectó?En otras palabras, de todas las veces que la respuesta era "sí", ¿cuántas veces el modelo lo detectó?n identify (classify) positive
instances. It is defined as
\begin{equation}
  \text{Se} = \frac{\text{TP}}{\text{TP} + \text{FN}}.
\end{equation}
In other words, out of all the times the answer was "yes," how many times was the model wrong?

\section{Specifity}
Specifity measures how well a model can correctly identify (classify)
negative instances, that is
\begin{equation}
  \text{Sp} = \frac{\text{TN}}{\text{TN} + \text{FP}}.
\end{equation}

\section{Precision}
This classification metric (\emph{precisión} in Spanish) measures the proportion of correctly predicted positive instances out of all instances predicted as positive, i.e., it is computed by
\begin{equation}
  \text{Pr} = \frac{\text{TP}}{\text{TP} + \text{FP}}.
\end{equation}
In other words, of all the times the model said "yes," how many times was it right?

\section{F1-score}
Classification metric that computes the harmonic mean of Pr and Se:
\begin{equation}
  \text{F1-score} = \frac{2\text{Pr}\text{Se}}{\text{Pr}+\text{Se}}.
\end{equation}
High F1-scores are correlated with a good equilibrium between precision and recall.

\section{Confusion matrix}
A table that summarizes the performance of a classification model by showing
\begin{table}{ccc}
  & Predicted Positive & Predicted Negative \\
  Actual Positive & TP & FN \\
  Actual Negative & FP & TN
\end{table}

\section{}
curva precisión-recuperación
\begin{equation}
  \text{AUC-PRC} = \sum_{i=1}^{t-1}(\text{R}_{i+1}-\text{R}_i)\frac{\text{P}_i+\text{P}_{i+1}}{2}
\end{equation}

\section{Epoch}
An epoch refers to one complete pass through the entire training dataset.

\section{Training dataset}
Collection of data used to teach the model. It's composed of input
features and their corresponding target labels.

\section{Validation dataset}
A subset of the training data used to evaluate the model's performance
when training.

\section{Test dataset}
Data used to evaluate the performance of a trained model.

\section{Batch}
During training, the dataset is ofted divided into smaller chunks
called batches.

\section{Training iteration}
One training iteration occurs when the during the training a single
batch of data has been used.

\section{Overfitting}
Overfitting happens when the model becomes too specialized to the
training dataset, performing poorly on unseen data.

\section{Early stopping}
To prevent overfitting, early stopping fialized the training when the
model's performance on the validation dataset starts to degrade.

\section{Batch normalization}
